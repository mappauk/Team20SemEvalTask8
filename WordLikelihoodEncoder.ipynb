{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qZXswcqie0Qr"
      },
      "outputs": [],
      "source": [
        "# only run on google runtime\n",
        "!pip install tensorflow-text\n",
        "!pip install tf-models-official\n",
        "!pip install tensorflow-addons\n",
        "!pip install scikit-learn\n",
        "!pip install datasets\n",
        "!pip install tqdm"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "uzBgUsHQgGbz"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "import tensorflow_hub as hub\n",
        "import tensorflow_text\n",
        "from official.nlp import optimization\n",
        "import tensorflow_addons as tfa\n",
        "import transformers\n",
        "import sklearn as sk"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lQZxzWuUgIz1"
      },
      "outputs": [],
      "source": [
        "# only run on google runtime\n",
        "# update file paths with location to subtask data\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "input_directory = '/content/drive/MyDrive/2023-2024 School Year/Fall Semester/Natural Language Processing/Project/Data'\n",
        "raw_train_data = input_directory + '/subtaskA_train_monolingual.jsonl'\n",
        "raw_dev_data = input_directory + '/subtaskA_dev_monolingual.jsonl'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "hq1CVLGegK78"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "\n",
        "def extract_data(filename):\n",
        "  text = []\n",
        "  with open(filename, 'r', encoding='utf-8') as f:\n",
        "    jlist = list(f)\n",
        "    for elem in jlist:\n",
        "      jsonData = json.loads(elem)\n",
        "      text.append(jsonData[\"text\"])\n",
        "  return text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "id": "viGiRg7agNtO"
      },
      "outputs": [],
      "source": [
        "train_text = extract_data(raw_train_data)\n",
        "dev_text = extract_data(raw_dev_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "NCGmA3F3gUHe"
      },
      "outputs": [],
      "source": [
        "# GPT Default\n",
        "gpt_default_tokenizer = transformers.AutoTokenizer.from_pretrained(\"gpt2\")\n",
        "gpt_default_encoder = transformers.TFGPT2LMHeadModel.from_pretrained(\"gpt2\")\n",
        "\n",
        "# OPT Default\n",
        "opt_default_tokenizer = transformers.AutoTokenizer.from_pretrained(\"facebook/opt-125m\")\n",
        "opt_default_encoder = transformers.TFOPTForCausalLM.from_pretrained(\"facebook/opt-125m\")\n",
        "\n",
        "models = [\n",
        "    (gpt_default_tokenizer, gpt_default_encoder),\n",
        "    (opt_default_tokenizer, opt_default_encoder),\n",
        "]\n",
        "softmax = tf.nn.softmax"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "2mJYaj7G630A"
      },
      "outputs": [],
      "source": [
        "gpt_default_tokenizer.pad_token = gpt_default_tokenizer.eos_token\n",
        "gpt_default_encoder.config.pad_token_id = gpt_default_encoder.config.eos_token_id"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "id": "0l9xkirhKJh3"
      },
      "outputs": [],
      "source": [
        "from tqdm import tqdm\n",
        "\n",
        "def encode_text(text_list, batch_size, models):\n",
        "  batch_encoded_text = []\n",
        "  batch_count = int((len(text_list) / batch_size))\n",
        "  if len(text_list) % batch_size != 0:\n",
        "    batch_count += 1\n",
        "  for i in tqdm(range(batch_count)):\n",
        "    batch_start = i*batch_size\n",
        "    batch_end = min(batch_start + batch_size, len(text_list))\n",
        "    batch_text = text_list[batch_start: batch_end]\n",
        "    current_batch_count = batch_end - batch_start\n",
        "    model_output = []\n",
        "    for tokenizer, model in models:\n",
        "      tokenized_data = tokenizer(batch_text, padding='max_length', return_tensors=\"tf\", max_length=512, truncation=True)\n",
        "      outputs = model(tokenized_data)\n",
        "      vocab_probs = softmax(outputs.logits)\n",
        "      flattened_probs = tf.reshape(vocab_probs, [vocab_probs.shape[0], -1])\n",
        "      indicies = tf.reshape(tf.tile(tf.range(tokenized_data['input_ids'].shape[1] - 1), [current_batch_count]), [current_batch_count, tokenized_data['input_ids'].shape[1] - 1])\n",
        "      indicies = indicies*vocab_probs.shape[2]\n",
        "      indicies = indicies + tokenized_data['input_ids'][:, 1:]\n",
        "      selected_probs = tf.gather(flattened_probs, indicies, axis=1, batch_dims=1)\n",
        "      model_output.append(selected_probs)\n",
        "    combined_model_probs = tf.stack(model_output, axis=-1)\n",
        "    batch_encoded_text.append(combined_model_probs)\n",
        "  return batch_encoded_text"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "8Yr7rVv04i_U"
      },
      "outputs": [],
      "source": [
        "train_text_encoded_batched = encode_text(train_text, 8, models)\n",
        "dev_text_encoded_batched = encode_text(dev_text, 8, models)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "DvkrKfTP15Hq"
      },
      "outputs": [],
      "source": [
        "# update paths with location to save encoded train and dev data\n",
        "rain_text_final_encoded = np.concatenate(train_text_encoded_batched)\n",
        "dev_text_final_encoded = np.concatenate(dev_text_encoded_batched)\n",
        "np.save(\"/content/drive/MyDrive/2023-2024 School Year/Fall Semester/Natural Language Processing/Project/train_final_encoded_probabilities.npy\", train_text_final_encoded)\n",
        "np.save(\"/content/drive/MyDrive/2023-2024 School Year/Fall Semester/Natural Language Processing/Project/dev_final_encoded_probabilities.npy\", dev_text_final_encoded)"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}